[
  {
    "objectID": "result.html",
    "href": "result.html",
    "title": "3. Results & Strategic Analysis",
    "section": "",
    "text": "We compare the Historical Strategy (what actually happened) against our Optimized Strategy (what the model recommends).\n\n\nCode\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\n# Set visual style\nsns.set_theme(style=\"whitegrid\")\n\n# --- LOAD RESULTS ---\ntry:\n    df = pd.read_csv('Data/results.csv')\n    \n    # SAFETY CHECK: Map column names automatically to avoid KeyErrors\n    col_map = {\n        'Price': 'Avg_Price' if 'Avg_Price' in df.columns else 'Price_Unit',\n        'Weight': 'Avg_Weight' if 'Avg_Weight' in df.columns else 'Weight_Unit'\n    }\n    \n    print(f\"Detected columns: Price column = '{col_map['Price']}', Weight column = '{col_map['Weight']}'\")\n\nexcept FileNotFoundError:\n    print(\"Error: 'data/results.csv' not found. Run '02_optimization_model.ipynb' first.\")\n\n\nDetected columns: Price column = 'Price_Unit', Weight column = 'Weight_Unit'\n\n\n\nFinancial Impact Analysis\n\n\nCode\n# 1. Historical Revenue (Sum of Demand * Price)\nhist_revenue = (df['Original_Demand'] * df[col_map['Price']]).sum()\n\n# 2. Optimized Strategy (Sum of Optimized Qty * Price)\nopt_revenue = (df['Optimized_Qty'] * df[col_map['Price']]).sum()\n\n# 3. Naive Baseline (Just cutting everything by 30%)\n# Use 0.75 if you used 75% capacity in your model\nscale_factor = 0.75\nnaive_revenue = (df['Original_Demand'] * scale_factor * df[col_map['Price']]).sum()\n\n# Calculate Improvement over a Naive cut\nimprovement = opt_revenue - naive_revenue\npct_gain = (improvement / naive_revenue) * 100\n\nprint(\"-\" * 30)\nprint(f\"Naive Strategy Revenue:   R$ {naive_revenue:,.2f}\")\nprint(f\"Optimized Strategy Revenue: R$ {opt_revenue:,.2f}\")\nprint(f\"Optimization Value-Add:     R$ {improvement:,.2f} (+{pct_gain:.2f}% improvement)\")\nprint(\"-\" * 30)\n\n\n------------------------------\nNaive Strategy Revenue:   R$ 10,056,637.46\nOptimized Strategy Revenue: R$ 12,167,050.16\nOptimization Value-Add:     R$ 2,110,412.70 (+20.99% improvement)\n------------------------------\n\n\n\n\nThe Optimization Strategy\n\n\nCode\n# A. Categories Deprioritized\ndf['Reduction'] = df['Original_Demand'] - df['Optimized_Qty']\nlosers = df[df['Reduction'] &gt; 0].sort_values(col_map['Weight'], ascending=False).head(5)\n\nprint(\"\\n--- TOP 5 CATEGORIES TO REDUCE ---\")\nprint(losers[['Category', col_map['Weight'], col_map['Price'], 'Reduction']])\n\n# B. Categories Prioritized \nwinners = df[df['Status'] == 'Full Demand Met'].sort_values(col_map['Price'], ascending=False).head(5)\n\nprint(\"\\n--- TOP 5 CATEGORIES TO PRIORITIZE ---\")\nprint(winners[['Category', col_map['Weight'], col_map['Price']]])\n\n\n\n--- TOP 5 CATEGORIES TO REDUCE ---\n                                          Category   Weight_Unit  Price_Unit  \\\n66                               moveis_escritorio  11390.454169  162.011059   \n65                                   moveis_quarto   9989.220183  183.750275   \n67  moveis_cozinha_area_de_servico_jantar_e_jardim   8852.850534  164.869644   \n72                                     moveis_sala   8092.532803  137.011054   \n68                       moveis_colchao_e_estofado   7557.894737  114.949474   \n\n    Reduction  \n66     1691.0  \n65      109.0  \n67      281.0  \n72      503.0  \n68       38.0  \n\n--- TOP 5 CATEGORIES TO PRIORITIZE ---\n                       Category  Weight_Unit   Price_Unit\n39                          pcs  7216.798030  1098.340542\n46  portateis_casa_forno_e_cafe  5074.894737   624.285658\n36           eletrodomesticos_2  8957.571429   476.124958\n37    agro_industria_e_comercio  3625.113208   342.124858\n20        instrumentos_musicais  3095.845588   281.616000\n\n\n\n\nVisualization\n\n\nCode\nrevenue_data = pd.DataFrame({\n    'Strategy': ['Naive Cut (Flat 30%)', 'Optimized Strategy (Simplex)'],\n    'Revenue': [naive_revenue, opt_revenue]\n})\n\nplt.figure(figsize=(10, 6))\nax = sns.barplot(data=revenue_data, x='Strategy', y='Revenue', palette=['#95a5a6', '#2ecc71'])\nplt.title('Why Optimize? Revenue with 25% Capacity Reduction', fontsize=14)\nplt.ylabel('Total Revenue (R$)')\n\n# Add values on top of bars\nfor p in ax.patches:\n    ax.annotate(f'R$ {p.get_height():,.0f}', \n                (p.get_x() + p.get_width() / 2., p.get_height()), \n                ha='center', va='center', xytext=(0, 10), textcoords='offset points', fontweight='bold')\n\nplt.ylim(0, opt_revenue * 1.2) # Give some space at the top\nplt.show()\n\n\nC:\\Users\\Lenovo\\AppData\\Local\\Temp\\ipykernel_22328\\2428717596.py:7: FutureWarning: \n\nPassing `palette` without assigning `hue` is deprecated and will be removed in v0.14.0. Assign the `x` variable to `hue` and set `legend=False` for the same effect.\n\n  ax = sns.barplot(data=revenue_data, x='Strategy', y='Revenue', palette=['#95a5a6', '#2ecc71'])"
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Product Prioritization",
    "section": "",
    "text": "1. Introduction\nOlist is a leading e-commerce marketplace in Brazil that connects small businesses to customers across the country.\nHowever, every logistics network has a breaking point. Olist has a limited operational handling capacity (defined by total weight and volume in their warehouses and shipping network). Because of this physical limitation, Olist cannot accept an infinite number of products.\n\nThe Business Challenge\nIf Olist fills its trucks with heavy, cheap items (like bags of cement), they lose money. If they fill them with light, expensive items (like watches), they make money. The challenge is finding the perfect mathematical balance.\n\n\n\n\n\n\nImportantResearch Question\n\n\n\nWhich product categories should Olist prioritize to maximize total revenue, given the strict constraints on historical handling capacity?\n\n\n\n\n\n2. Methodology\nTo solve this, we apply Linear Programming (Simplex Method) following this workflow:\n\nData Mining: Extract historical sales behavior and physical product attributes.\nPreprocessing: Clean missing values, handle outliers, and merge datasets.\nMathematical Modeling: Formulate an Objective Function (\\(Z\\)) and Constraints (\\(K\\)).\nOptimization: Use the Python PuLP library to solve for the optimal quantity \\(x\\).\nResults: Interpret the optimized solution to guide business strategy.\n\n\n\n3. Data Overview\nWe utilized three core datasets from the Olist public database. Below is the dictionary of attributes available in each file.\n\n1. Sales Data (olist_order_items)\nContains the individual transaction lines.\n\norder_id: Unique identifier of the order.\norder_item_id: Sequential number identifying number of items included in the same order.\nproduct_id: Unique identifier used to link to product specs.\nseller_id: Unique identifier of the seller.\nshipping_limit_date: The seller shipping limit date for handling the order.\nprice: The item price (Revenue Coefficient \\(P_i\\)).\nfreight_value: Item freight cost.\n\n\n\n2. Product Specs (olist_products)\nDefines the physical characteristics and metadata of the inventory.\n\nproduct_id: Unique identifier of the product.\nproduct_category_name: The category name (Decision Variable Index \\(i\\)).\nproduct_name_lenght: Number of characters extracted from the product name.\nproduct_description_lenght: Number of characters extracted from the product description.\nproduct_photos_qty: Number of product published photos.\nproduct_weight_g: Product weight in grams (Capacity Coefficient \\(W_i\\)).\nproduct_length_cm: Product length in centimeters.\nproduct_height_cm: Product height in centimeters.\nproduct_width_cm: Product width in centimeters.\n\n\n\n3. Payments (olist_order_payments)\nContains the payment details for validation purposes.\n\norder_id: Unique identifier of an order (Used for filtering valid sales).\npayment_sequential: Sequence of payments.\npayment_type: Method of payment (credit card, voucher, boleto, debit card).\npayment_installments: Number of installments chosen by the customer.\npayment_value: Transaction value.\n\n\n\n\n4. Data Source Mapping\nWe formulated the problem using the following variables mapped from the Olist dataset:\n\n\n\n\n\n\n\n\n\nBusiness Concept\nAttribute\nDataset Source\nRole in Model\n\n\n\n\nProduct Category\nproduct_category_name\nolist_products\nDecision Variable (\\(x_i\\)): The quantity to sell per category.\n\n\nUnit Revenue\nprice\nolist_order_items\nObjective (\\(Z\\)): Maximize the sum of Price \\(\\times\\) Quantity.\n\n\nCapacity\nproduct_weight_g\nolist_products\nConstraint (\\(K\\)): Total weight cannot exceed the limit.\n\n\n\n\n\n5. Mathematical Formulation\nWe model this problem as a Resource Allocation Problem (specifically, a variant of the Knapsack Problem).\n\nSets & Indices\n\n\\(I\\): The set of all product categories.\n\\(i\\): Index representing a specific category (e.g., \\(i = \\text{Watches}\\)).\n\n\n\nParameters (Data Inputs)\nThese values were calculated in the Data Analysis phase:\n\n\\(P_i\\): Average Price (Revenue) per unit of category \\(i\\).\n\\(W_i\\): Average Weight (Capacity Cost) per unit of category \\(i\\).\n\\(D_i\\): Maximum Demand (Historical sales count) for category \\(i\\).\n\\(K\\): Total System Capacity (Total weight limit).\n\n\n\nDecision Variables\n\n\\(x_i\\): The quantity of items to include in the product mix for category \\(i\\).\n\nConstraint: \\(x_i\\) must be a non-negative Integer (\\(x_i \\in \\mathbb{Z}^+\\)).\n\n\n\n\n\nThe Linear Program\n1. Objective Function (Maximize Revenue) We want to choose quantities (\\(x_i\\)) that maximize total sales value: \\[ \\text{Maximize } Z = \\sum_{i \\in I} (P_i \\cdot x_i) \\]\n2. Capacity Constraint The total weight of the selected mix cannot exceed the warehouse limit: \\[ \\sum_{i \\in I} (W_i \\cdot x_i) \\leq K \\]\n3. Demand Constraints We cannot optimize for more sales than the market actually wants: \\[ x_i \\leq D_i \\quad \\forall i \\in I \\]\n4. Non-Negativity & Integrality We cannot sell negative items or half an item: \\[ x_i \\geq 0, \\quad x_i \\text{ is Integer} \\]"
  },
  {
    "objectID": "data.html",
    "href": "data.html",
    "title": "1. Data Analysis & Preparation",
    "section": "",
    "text": "We begin by loading the raw datasets and merging them to create a unified view of “Sales vs. Logistics Cost”.\n\n\nCode\nimport pandas as pd \nimport os\n\ntry:\n    # The \"..\" means go up one level to the main folder\n    items = pd.read_csv('Data/olist_order_items_dataset.csv')\n    products = pd.read_csv('Data/olist_products_dataset.csv')\n    payments = pd.read_csv('Data/olist_order_payments_dataset.csv')\n    \n    if items.empty or products.empty or payments.empty:\n        raise ValueError(\"One or more datasets are empty. Check the content of the CSV files.\")\n    \n    print(\"Datasets loaded successfully.\")\nexcept FileNotFoundError:\n    print(\"Error: CSV files not found. Check your 'data' folder location.\")\nexcept ValueError as e:\n    print(e)\n\n\nDatasets loaded successfully.\n\n\n\nDataset Overview\n\n\nCode\n# Check shapes and missing values\nfor name, df in {'Items': items, 'Products': products, 'Payments': payments}.items():\n    print(f\"{name} Dataset: {df.shape[0]} rows, {df.shape[1]} columns\")\n    print(f\"Missing values in {name} dataset:\\n{df.isna().sum()}\\n\")\n\n\nItems Dataset: 112650 rows, 7 columns\nMissing values in Items dataset:\norder_id               0\norder_item_id          0\nproduct_id             0\nseller_id              0\nshipping_limit_date    0\nprice                  0\nfreight_value          0\ndtype: int64\n\nProducts Dataset: 32951 rows, 9 columns\nMissing values in Products dataset:\nproduct_id                      0\nproduct_category_name         610\nproduct_name_lenght           610\nproduct_description_lenght    610\nproduct_photos_qty            610\nproduct_weight_g                2\nproduct_length_cm               2\nproduct_height_cm               2\nproduct_width_cm                2\ndtype: int64\n\nPayments Dataset: 103886 rows, 5 columns\nMissing values in Payments dataset:\norder_id                0\npayment_sequential      0\npayment_type            0\npayment_installments    0\npayment_value           0\ndtype: int64\n\n\n\n\n\nClean & Merge\n\n\nCode\n# --- MERGE & CLEAN ---\n## 1. Filter for valid paid orders\nif 'order_id' in payments.columns and 'order_id' in items.columns:\n    valid_orders = payments['order_id'].unique()\n    original_rows = items.shape[0]\n    items = items[items['order_id'].isin(valid_orders)]\n    print(f\"Filtered valid orders. Rows reduced from {original_rows} to {items.shape[0]}.\")\nelse:\n    print(\"Error: 'order_id' column missing in one of the datasets.\")\n\n# 2. Merge Items with Products (Link Price to Weight)\nif 'product_id' in items.columns and 'product_id' in products.columns:\n    df = pd.merge(items, products, on='product_id', how='inner')\n    print(f\"Merged dataset created with {df.shape[0]} rows and {df.shape[1]} columns.\")\nelse:\n    print(\"Error: 'product_id' column missing in one of the datasets.\")\n\n# 3. Drop Errors (Missing values or 0s)\nbefore_cleaning = df.shape[0]\ndf = df.dropna(subset=['product_category_name', 'product_weight_g', 'price'])\ndf = df[(df['product_weight_g'] &gt; 0) & (df['price'] &gt; 0)]\nprint(f\"Cleaned dataset. Rows reduced from {before_cleaning} to {df.shape[0]}.\")\n\n\nFiltered valid orders. Rows reduced from 112650 to 112647.\nMerged dataset created with 112647 rows and 15 columns.\nCleaned dataset. Rows reduced from 112647 to 111035.\n\n\n\n\nCode\n# 4. Outlier Handling\n# We cap items at 30kg. Items heavier than this usually require special freight \n# logic, so we exclude them to focus on standard warehouse capacity.\ndf_clean = df[df['product_weight_g'] &lt;= 30000].copy()\nprint(f\"Original Rows: {len(df)}\")\nprint(f\"Cleaned Rows:  {len(df_clean)}\")\n\n\nOriginal Rows: 111035\nCleaned Rows:  111032\n\n\n\n\nAggregate & Save Parameters\n\n\nCode\n# Aggregate\nlp_data = df_clean.groupby('product_category_name').agg({\n    'price': 'mean', # Pi: average revenue\n    'product_weight_g': 'mean', # wi : average  weight\n    'order_item_id': 'count' # Di : total historical Demand\n}).reset_index()\n# rename columns\nlp_data.columns = ['Category', 'P_i', 'W_i', 'D_i']\nlp_data.to_csv('Data/lp_parameters.csv', index=False)\nwith open('Data/capacity.txt', 'w') as f:\n    f.write(str(df_clean['product_weight_g'].sum()))\nprint(\"Success! Created 'data/lp_parameters.csv' and 'data/capacity.txt'\")\n\n\nSuccess! Created 'data/lp_parameters.csv' and 'data/capacity.txt'"
  },
  {
    "objectID": "model.html",
    "href": "model.html",
    "title": "2. Mathematical Optimization Model (PuLP)",
    "section": "",
    "text": "Code\nimport pandas as pd\nimport pulp\n\n# --- STEP 1: LOAD DATA ---\ntry:\n    # Load the parameters table (Pi, Wi, Di)\n    lp_data = pd.read_csv('Data/lp_parameters.csv')\n    if lp_data.empty:\n        raise ValueError(\"Error: 'lp_parameters.csv' is empty.\")\n    \n    # Load the scalar capacity value (K)\n    with open('Data/capacity.txt', 'r') as f:\n        original_K = float(f.read())\n        \n    # --- THE FIX: INTRODUCE SCARCITY ---\n    # We reduce capacity to 75% of the historical volume. \n    # This creates a \"Limited Handling Capacity\" as required by the problem.\n    K = original_K * 0.75 \n\n    print(f\"Data Loaded Successfully.\")\n    print(f\"Categories to Optimize: {len(lp_data)}\")\n    print(f\"Original Historical Weight: {original_K:,.0f} g\")\n    print(f\"Simulated Capacity Limit (75%): {K:,.0f} g\")\n\nexcept FileNotFoundError:\n    print(\"Error: Input files not found. Please run '01_data_preparation.ipynb' first.\")\nexcept ValueError as e:\n    print(e)\n\n\nData Loaded Successfully.\nCategories to Optimize: 73\nOriginal Historical Weight: 233,070,066 g\nSimulated Capacity Limit (75%): 174,802,550 g\n\n\n\nDefine Model\n\n\nCode\nif 'Category' in lp_data.columns:\n    categories = lp_data['Category'].tolist()\nelse:\n    raise KeyError(\"Error: 'Category' column missing.\")\n\n# 1. Initialize Model (Maximization)\nmodel = pulp.LpProblem(\"Olist_Revenue_Optimization\", pulp.LpMaximize)\n\n# 2. Define Decision Variables\nx = pulp.LpVariable.dicts(\"Qty\", categories, lowBound=0, cat='Integer')\n\n# 3. Objective Function: Maximize Total Revenue (Price * Quantity)\nmodel += pulp.lpSum([lp_data.loc[i, 'P_i'] * x[cat] \n                     for i, cat in enumerate(categories)])\n\n# 4. Add Capacity Constraint: Total Weight handled must be &lt;= K\nmodel += pulp.lpSum([lp_data.loc[i, 'W_i'] * x[cat] \n                     for i, cat in enumerate(categories)]) &lt;= K\n\n# 5. Add Demand Constraints: Quantity handled &lt;= Market Demand\nfor i, cat in enumerate(categories):\n    model += x[cat] &lt;= lp_data.loc[i, 'D_i']\n\n\n\n\nSolve\n\n\nCode\n# Solve using the CBC solver\nmodel.solve(pulp.PULP_CBC_CMD(msg=0))\n\n# Check the status\nstatus = pulp.LpStatus[model.status]\nprint(f\"Optimization Status: {status}\")\n\n\nOptimization Status: Optimal\n\n\n\n\nProcess & Save Results\n\n\nCode\nif status == 'Optimal':\n    results = []\n\n    for i, cat in enumerate(categories):\n        optimized_qty = x[cat].varValue\n        demand = lp_data.loc[i, 'D_i']\n\n        # Determine Status logic\n        if optimized_qty &gt;= demand:\n            res_status = 'Full Demand Met'\n        elif optimized_qty &gt; 0:\n            res_status = 'Prioritized (Partial)'\n        else:\n            res_status = 'Deprioritized (Cut)'\n\n        results.append({\n            'Category': cat,\n            'Price_Unit': lp_data.loc[i, 'P_i'],\n            'Weight_Unit': lp_data.loc[i, 'W_i'],\n            'Original_Demand': demand,\n            'Optimized_Qty': optimized_qty,\n            'Status': res_status\n        })\n\n    results_df = pd.DataFrame(results)\n\n    # Sort results to show which items were \"Reduced/Cut\" at the bottom\n    results_df = results_df.sort_values(by=\"Optimized_Qty\", ascending=False)\n\n    # Save results\n    results_df.to_csv('Data/results.csv', index=False)\n    print(\"Results saved to 'data/results.csv'\")\n    \n    # Display top and bottom to see the \"Optimization\" in action\n    print(\"\\n--- Top Categories (Prioritized) ---\")\n    print(results_df.head(10)[['Category', 'Original_Demand', 'Optimized_Qty', 'Status']])\n    \n    print(\"\\n--- Bottom Categories (Reduced due to capacity) ---\")\n    print(results_df.tail(10)[['Category', 'Original_Demand', 'Optimized_Qty', 'Status']])\nelse:\n    print(\"No feasible solution found.\")\n\n\nResults saved to 'data/results.csv'\n\n--- Top Categories (Prioritized) ---\n                  Category  Original_Demand  Optimized_Qty           Status\n13         cama_mesa_banho            11104        11104.0  Full Demand Met\n11            beleza_saude             9667         9667.0  Full Demand Met\n32           esporte_lazer             8641         8641.0  Full Demand Met\n54        moveis_decoracao             8334         8334.0  Full Demand Met\n44  informatica_acessorios             7827         7827.0  Full Demand Met\n66      relogios_presentes             5991         5991.0  Full Demand Met\n70               telefonia             4545         4545.0  Full Demand Met\n40      ferramentas_jardim             4347         4347.0  Full Demand Met\n8               automotivo             4235         4235.0  Full Demand Met\n12              brinquedos             4117         4117.0  Full Demand Met\n\n--- Bottom Categories (Reduced due to capacity) ---\n                                          Category  Original_Demand  \\\n68                         sinalizacao_e_seguranca              199   \n67                              seguros_e_servicos                2   \n56                                   moveis_quarto              109   \n55                               moveis_escritorio             1691   \n53  moveis_cozinha_area_de_servico_jantar_e_jardim              281   \n52                       moveis_colchao_e_estofado               38   \n50                                malas_acessorios             1092   \n41                                          flores               33   \n43                   industria_comercio_e_negocios              268   \n57                                     moveis_sala              503   \n\n    Optimized_Qty                 Status  \n68            3.0  Prioritized (Partial)  \n67            2.0        Full Demand Met  \n56            0.0    Deprioritized (Cut)  \n55            0.0    Deprioritized (Cut)  \n53            0.0    Deprioritized (Cut)  \n52            0.0    Deprioritized (Cut)  \n50            0.0    Deprioritized (Cut)  \n41            0.0    Deprioritized (Cut)  \n43            0.0    Deprioritized (Cut)  \n57            0.0    Deprioritized (Cut)"
  }
]